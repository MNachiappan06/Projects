{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "R8_Internal_Lab_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NFfDTfhlaEI_"
      },
      "source": [
        "# Transfer Learning MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rNwbqCFRaEJC"
      },
      "source": [
        "* Train a simple convnet on the MNIST dataset the first 5 digits [0-4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5-9]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Dnzaw1i5sXF"
      },
      "source": [
        "## MNIST Dataset\n",
        "The MNIST database contains 60,000 training images and 10,000 testing images taken from American Census Bureau employees and American high school students. The MNIST dataset is one of the most common datasets used for image classification and accessible from many different sources. In fact, even Tensorflow and Keras allow us to import and download the MNIST dataset directly from their API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bpUULy1Z5sXF"
      },
      "source": [
        "Let's import keras and load MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KiG7IPhm5sXG",
        "colab": {}
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZqUiJM_Z5sXL",
        "outputId": "422f2c51-5478-4b38-9dab-57d6163ca2dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.backend import backend\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUqMAc5XDkeS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "490fde59-c865-4839-ded7-d0666c5b3067"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCFLiXo-DqE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3b50b6f-aa82-4c2d-dd95-4af6f70084f2"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc-7PcvNDtyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a51ef51-323a-4286-cfdc-00193ef04d9e"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPmrARp6DwNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4211ebd8-dc08-4568-9cf2-6f61c99a94c8"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RVw4wsuW5sXO"
      },
      "source": [
        "X_train and X_test contain greyscale RGB codes (from 0 to 255) while y_train and y_test contains labels from 0 to 9 which represents which number they actually are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xgQ86Vhw5sXP"
      },
      "source": [
        "Let's visualize some numbers using matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VZwg00gO5sXQ",
        "outputId": "be6256c4-3749-44d8-ed0d-349a58aed084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(\"Label: {}\".format(y_train[1000]))\n",
        "plt.imshow(X_train[1000], cmap='gray')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4bee8c0630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCDtbIrGD3Ti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "0d744ebb-a14c-422c-cdd3-0942b1cb56b4"
      },
      "source": [
        "plt.imshow(X_train[255], cmap='gray')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4bfc2d6278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEHYgSAIOxAEYQeC+H/s7WCC9RzhXgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBdvsZxED8Zn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "255a6d5c-0549-4c7e-bc23-636c2982394c"
      },
      "source": [
        "plt.imshow(X_train[255])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4bee2e27f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rldo4KU3ERSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7783c71e-35d5-4773-96f3-0566926886aa"
      },
      "source": [
        "import numpy as np\n",
        "y_train[255]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na1aYklJE5UL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84789716-a158-49a2-b77a-4c2e9460be9e"
      },
      "source": [
        "y_test[255]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p64mhwp95sXS"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XxNAiWYd5sXT"
      },
      "source": [
        "### Create two datasets\n",
        "- First having digits from 0 to 4\n",
        "- Second having digits from 5 to 9\n",
        "\n",
        "Hint: use labels to separate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O1Rk3-XGDcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()  #Splitting the data into train and test sets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAohOEUSG2ds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88c8bd29-5747-461a-8ab9-6ecb0c6348cc"
      },
      "source": [
        "x_train[y_train < 5][0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         54, 227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60,\n",
              "        224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252,\n",
              "        252, 252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253,\n",
              "        253, 190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252,\n",
              "        179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,\n",
              "         84,   0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,\n",
              "         28,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,\n",
              "          0,   0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,\n",
              "          0,   0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85,\n",
              "        178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252,\n",
              "        252, 252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252,\n",
              "        233, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,\n",
              "         37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kbuSEHKQVAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1807m1CL5sXT",
        "colab": {}
      },
      "source": [
        "x_train_les5 = x_train[y_train < 5] #will give the data that is less that 5(0-4), based on train data on y_train, this will be derived on the based the index\n",
        "                                    #x_train and y_train will have same index hence y_train < 5, indexes will be picked and the same index will\n",
        "                                    # be hit picked in x_train and the data is stored\n",
        "                                    \n",
        "y_train_les5 = y_train[y_train < 5] #will give the data that is less that 5(0-4), based on train data on y_train\n",
        "x_test_les5 = x_test[y_test < 5]\n",
        "y_test_les5 = y_test[y_test < 5]\n",
        "\n",
        "x_train_gret5 = x_train[y_train >= 5]  #will give the data that is more that 5(5-9), based on train data on y_train\n",
        "y_train_gret5 = y_train[y_train >= 5] - 5\n",
        "x_test_gret5 = x_test[y_test >= 5]\n",
        "y_test_gret5 = y_test[y_test >= 5] - 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qX4ws2OLw4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_greater5 = y_train[y_train >= 5]  #will give the data that is more that 5(5-9), based on train data on y_train\n",
        "y_test_greater5 = y_test[y_test >= 5] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOHwc-i5MIR-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7e48a23-6b2f-48a6-ba2f-32bc577e257d"
      },
      "source": [
        "print(y_train_greater5.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(29404,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6JgIJaKMN62",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d675f3b-d1e6-4d16-fcc8-f4c92c017f51"
      },
      "source": [
        "print(y_test_greater5.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4861,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M9jKcF1z5sXV"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NMo7lvwQ5sXW"
      },
      "source": [
        "### Print shape of the data\n",
        "- print shape of all variables of both the datasets you created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kH7ZjEoH5sXW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ae29f762-e811-4863-8e42-b66bb1d83bbd"
      },
      "source": [
        "print(\"X Train less than 5\\n\",x_train_les5.shape)\n",
        "print(\"X Test less than 5\\n\",x_test_les5.shape)\n",
        "\n",
        "print(\"Y Train less than 5\\n\",y_train_les5.shape)\n",
        "print(\"Y Test less than 5\\n\",y_test_les5.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Train less than 5\n",
            " (30596, 28, 28)\n",
            "X Test less than 5\n",
            " (5139, 28, 28)\n",
            "Y Train less than 5\n",
            " (30596,)\n",
            "Y Test less than 5\n",
            " (5139,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCPEzsUvLDAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "08bccebf-b863-4c62-c15e-1022e19759f5"
      },
      "source": [
        "print(\"X Train greater than 5\\n\",x_train_gret5.shape)\n",
        "print(\"X Test greater than 5\\n\",x_test_gret5.shape)\n",
        "\n",
        "print(\"Y Train greater than 5\\n\",y_train_gret5.shape)\n",
        "print(\"Y Test greater than 5\\n\",y_test_gret5.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Train greater than 5\n",
            " (29404, 28, 28)\n",
            "X Test greater than 5\n",
            " (4861, 28, 28)\n",
            "Y Train greater than 5\n",
            " (29404,)\n",
            "Y Test greater than 5\n",
            " (4861,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IUU4PkKU5sXY"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4I8ajqdt5sXY"
      },
      "source": [
        "### Reshape data\n",
        "- reshape first dataset\n",
        "- To be able to use the dataset in Keras, we need 4-dims numpy arrays. \n",
        "- reshape features to pass it to a Conv2D layer\n",
        "- channel = 1\n",
        "- reshape features of first dataset only\n",
        "- do not reshape labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "38wgBEcz5sXa",
        "colab": {}
      },
      "source": [
        "x_train_reshaped = x_train_les5.reshape(x_train_les5.shape[0], 28, 28, 1) #Reshaping the x_variables ,where x_train_les5.shape[0] = 30596\n",
        "x_test_reshaped = x_test_les5.reshape(x_test_les5.shape[0], 28, 28, 1)  #Reshaping the x_variables ,where x_test_les5.shape[0] = 5139\n",
        "input_shape = (28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAp6l-boOTXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c7ffdbb-606b-4b74-ea3b-81e74704ad07"
      },
      "source": [
        "x_train_reshaped.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30596, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZGJr8lWOWlU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdaff2af-fbb9-4f04-f057-b0722f90ed99"
      },
      "source": [
        "x_test_reshaped.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5139, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUHk2hGRSXIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2d137fb-5410-4b76-899b-82c52400ffbb"
      },
      "source": [
        "y_train_les5.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30596,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9LTGHWxSXTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20474833-dc3a-48ab-f7e6-35e664d45e2c"
      },
      "source": [
        "y_test_les5.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5139,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_5H-BtNm5sXg"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2ahCMtCl5sXh"
      },
      "source": [
        "### Normalize data\n",
        "- normalize first dataset\n",
        "- we must normalize our data as it is always required in neural network models\n",
        "- we can achieve this by dividing the RGB codes to 255 (which is the maximum RGB code minus the minimum RGB code)\n",
        "- normalize X_train and X_test\n",
        "- make sure that the values are float so that we can get decimal points after division"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z4mti7pg5sXj",
        "colab": {}
      },
      "source": [
        "x_train_normalized =  x_train_reshaped.astype(\"float32\") / 255\n",
        "x_test_normalized = x_test_reshaped.astype(\"float32\") / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TfQ6545D5sXp"
      },
      "source": [
        "### Print shape of data and number of images\n",
        "- for first dataset\n",
        "- print shape of X_train\n",
        "- print number of images in X_train\n",
        "- print number of images in X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uQfQXZMo5sXp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "160800bf-bdbb-4232-d230-73e3814f028d"
      },
      "source": [
        "x_train_normalized.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30596, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a387C2MnQuL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6961939-ae2a-4057-e5ce-fab384f87217"
      },
      "source": [
        "x_test_normalized.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5139, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9oFjomSh5sXu"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2lEFQQNk5sXu"
      },
      "source": [
        "### One-hot encode the class vector\n",
        "- encode labels of first dataset\n",
        "- convert class vectors (integers) to binary class matrix\n",
        "- convert y_train and y_test\n",
        "- number of classes: 5\n",
        "- we are doing this to use categorical_crossentropy as loss\n",
        "\n",
        "Hint: you can use keras.utils.to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjy_CTYpTNiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6aacf9cc-3280-4a5f-81c2-feac95f1d180"
      },
      "source": [
        "import numpy as np\n",
        "np.unique(y_train_les5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT-WQGY3TOdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40221e19-3fa3-4a21-e05b-98a13c32fca3"
      },
      "source": [
        "np.unique(y_test_les5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek15OplIel92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8435f50-4b8f-4758-d4eb-e9b3f1659fa6"
      },
      "source": [
        "np.unique(y_train_gret5)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1dCYav3ewLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ef928a2-b75b-4605-c8ff-b9233953fe95"
      },
      "source": [
        "np.unique(y_test_gret5)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6OnV6SfTfcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "962d12c8-2552-48c9-dce7-990d7622006f"
      },
      "source": [
        "np.unique(y_train_greater5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S1SbvLDTvS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c47f8cb9-200f-44f2-8da2-4141a2a8e847"
      },
      "source": [
        "np.unique(y_train_greater5)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv8H3OYpUGWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aejx3Zb35sXv",
        "colab": {}
      },
      "source": [
        "y_train_class = keras.utils.to_categorical(y_train_les5, 5)\n",
        "y_test_class = keras.utils.to_categorical(y_test_les5, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlkiipRA5sXw"
      },
      "source": [
        "## Question 6\n",
        "We will build our model by using high level Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KzYMC_xm5sXx"
      },
      "source": [
        "### Initialize a sequential model\n",
        "- define a sequential model\n",
        "- add 2 convolutional layers\n",
        "    - no of filters: 32\n",
        "    - kernel size: 3x3\n",
        "    - activation: \"relu\"\n",
        "    - input shape: (28, 28, 1) for first layer\n",
        "- add a max pooling layer of size 2x2\n",
        "- add a dropout layer\n",
        "    - dropout layers fight with the overfitting by disregarding some of the neurons while training\n",
        "    - use dropout rate 0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mByZcfRSVswk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mDr-HKl-5sXx",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LXbUUFEVfJ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "ff926fe1-44ee-4258-c0a7-db359616a957"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
            "=================================================================\n",
            "Total params: 18,816\n",
            "Trainable params: 18,816\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVJ6wegSWREL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#With filter size 32\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLn7bPqAWbbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "d80b16a7-a86d-42f5-f699-06b1c2abe2b2"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 11, 11, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 5, 5, 32)          0         \n",
            "=================================================================\n",
            "Total params: 9,568\n",
            "Trainable params: 9,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k2RaPWiP5sXz"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ajGIM6t5sXz"
      },
      "source": [
        "### Add classification layers\n",
        "- do this after doing question 6\n",
        "- flatten the data\n",
        "    - add Flatten later\n",
        "    - flatten layers flatten 2D arrays to 1D array before building the fully connected layers\n",
        "- add 2 dense layers\n",
        "    - number of neurons in first layer: 128\n",
        "    - number of neurons in last layer: number of classes\n",
        "    - activation function in first layer: relu\n",
        "    - activation function in last layer: softmax\n",
        "    - we may experiment with any number of neurons for the first Dense layer; however, the final Dense layer must have neurons equal to the number of output classes\n",
        "- you can add a dropout layer in between, if necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jBxWAN265sX0",
        "colab": {}
      },
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu',name= 'dense_1'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='softmax',name= 'dense_2'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKq6cpKHXq_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "403c6282-b894-4583-b07b-d19d0d9806f5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 224,389\n",
            "Trainable params: 224,389\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lhtm4d5K5sX1"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SmXg8EaF5sX2"
      },
      "source": [
        "### Compile and fit the model\n",
        "- compile your model\n",
        "    - loss: \"categorical_crossentropy\"\n",
        "    - metrics: \"accuracy\"\n",
        "    - optimizer: \"sgd\"\n",
        "- fit your model\n",
        "    - give train data - features and labels\n",
        "    - batch size: 128\n",
        "    - epochs: 10\n",
        "    - give validation data - features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cgclxC8s5sX4",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSqbo7x1ZsY0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "36a23f78-9443-47fe-b998-e22b7c6637e1"
      },
      "source": [
        "#Training on the dataset\n",
        "model_result = model.fit(x_train_normalized, y_train_class,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test_normalized, y_test_class))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 30596 samples, validate on 5139 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "30596/30596 [==============================] - 17s 563us/step - loss: 1.0647 - acc: 0.6418 - val_loss: 0.3119 - val_acc: 0.9370\n",
            "Epoch 2/10\n",
            "30596/30596 [==============================] - 1s 46us/step - loss: 0.3278 - acc: 0.8973 - val_loss: 0.1257 - val_acc: 0.9656\n",
            "Epoch 3/10\n",
            "30596/30596 [==============================] - 1s 45us/step - loss: 0.2254 - acc: 0.9294 - val_loss: 0.0924 - val_acc: 0.9714\n",
            "Epoch 4/10\n",
            "30596/30596 [==============================] - 1s 46us/step - loss: 0.1850 - acc: 0.9416 - val_loss: 0.0802 - val_acc: 0.9768\n",
            "Epoch 5/10\n",
            "30596/30596 [==============================] - 1s 46us/step - loss: 0.1581 - acc: 0.9521 - val_loss: 0.0736 - val_acc: 0.9774\n",
            "Epoch 6/10\n",
            "30596/30596 [==============================] - 1s 46us/step - loss: 0.1407 - acc: 0.9564 - val_loss: 0.0614 - val_acc: 0.9811\n",
            "Epoch 7/10\n",
            "30596/30596 [==============================] - 1s 46us/step - loss: 0.1315 - acc: 0.9599 - val_loss: 0.0540 - val_acc: 0.9831\n",
            "Epoch 8/10\n",
            "30596/30596 [==============================] - 1s 46us/step - loss: 0.1168 - acc: 0.9646 - val_loss: 0.0507 - val_acc: 0.9838\n",
            "Epoch 9/10\n",
            "30596/30596 [==============================] - 1s 45us/step - loss: 0.1090 - acc: 0.9663 - val_loss: 0.0464 - val_acc: 0.9844\n",
            "Epoch 10/10\n",
            "30596/30596 [==============================] - 1s 45us/step - loss: 0.0996 - acc: 0.9700 - val_loss: 0.0436 - val_acc: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oSVZUu3p5sX5"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y5TQ3yLV5sX6"
      },
      "source": [
        "### Evaluate model\n",
        "- evaluate your model and get accuracy\n",
        "- use test features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bBvuD3ba5sX7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "836f83ca-e46e-470d-dc28-66ca2c04fdc6"
      },
      "source": [
        "score = model.evaluate(x_test_normalized, y_test_class) \n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5139/5139 [==============================] - 0s 64us/step\n",
            "Test loss: 0.043607464181427816\n",
            "Test accuracy: 0.9848219498768696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8aUzOh9m5sX-"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "srd-YYNH5sX-"
      },
      "source": [
        "## Transfer learning\n",
        "Now we will apply this model on second dataset (5-9 digits)\n",
        "\n",
        "- fix the first convolution layers so that the weights in the convolution layers dont get updated in the process of training\n",
        "- get the second dataset\n",
        "- train the last 2 dense layers\n",
        "- predict the accuracy and loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KvhdH7D55sYA"
      },
      "source": [
        "### Make only dense layers trainable\n",
        "- set trainalble = False for all layers other than Dense layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "brN7VZHFaEJ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "0aefd613-4cdd-49da-ee6d-edd59e30f6db"
      },
      "source": [
        "#Freezing layers in the model which don't have 'dense' in their name\n",
        "for layer in model.layers:\n",
        "  if('dense' not in layer.name): #prefix detection to freeze layers which does not have dense\n",
        "    #Freezing a layer\n",
        "    layer.trainable = False\n",
        "\n",
        "#Module to print colourful statements\n",
        "from termcolor import colored\n",
        "\n",
        "#Check which layers have been frozen \n",
        "for layer in model.layers:\n",
        "  print (colored(layer.name, 'blue'))\n",
        "  print (colored(layer.trainable, 'red'))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mconv2d_3\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mmax_pooling2d_3\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mconv2d_4\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mmax_pooling2d_4\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdropout_2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mflatten_5\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdense_1\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n",
            "\u001b[34mdropout_5\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdense_2\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FYR9VGzO5sYE"
      },
      "source": [
        "### Modify data\n",
        "- in your second data, class labels will start from 5 to 9 but for keras.utils.to_categorical the labels should start from 0\n",
        "- so you need to subtract 5 from train and test labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5OLViq7f-RD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "dba6a173-3335-46cd-e6a7-3c4798cb56a4"
      },
      "source": [
        "print(\"X Train greater than 5\\n\",x_train_gret5.shape)\n",
        "print(\"X Test greater than 5\\n\",x_test_gret5.shape)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Train greater than 5\n",
            " (29404, 28, 28)\n",
            "X Test greater than 5\n",
            " (4861, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_W6MlShfSYl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a0f5afb-f996-4a40-9a7c-c6d48f193f51"
      },
      "source": [
        "np.unique(y_train_greater5) #There values are not subtracted(not processed)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtU6-H5pfUTL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9254405-e8a6-439b-bc08-808d02beede4"
      },
      "source": [
        "np.unique(y_test_greater5)  #There values are not subtracted(not processed)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lC5W75L35sYF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24f83438-2da8-4c50-8d07-591d13efc1a9"
      },
      "source": [
        "np.unique(y_train_gret5) #the values are converted(subtracted) in the first step"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNju_U3pfD6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5445390-b01b-45b5-8515-ad41bd8da5d3"
      },
      "source": [
        "np.unique(y_test_gret5) #the values are converted(subtracted) in the first step"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YGY3OTBt5sYG"
      },
      "source": [
        "### Reshape data\n",
        "- reshape second dataset\n",
        "- To be able to use the dataset in Keras, we need 4-dims numpy arrays. \n",
        "- reshape features to pass it to a Conv2D layer\n",
        "- channel = 1\n",
        "- reshape features of first dataset only\n",
        "- do not reshape labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0V7RUlRD5sYH",
        "colab": {}
      },
      "source": [
        "x_train_gret5 = x_train_gret5.reshape(x_train_gret5.shape[0], 28, 28, 1)   ## grey scale image and hence adding 1\n",
        "x_test_gret5 = x_test_gret5.reshape(x_test_gret5.shape[0], 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2VAHUvNgV6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "75c8cb1e-1d13-45d7-f33d-dffd1cb6ced7"
      },
      "source": [
        "print(x_train_gret5.shape)\n",
        "print(x_test_gret5.shape)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(29404, 28, 28, 1)\n",
            "(4861, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c7omqMQH5sYJ"
      },
      "source": [
        "### Normalize data\n",
        "- normalize second data\n",
        "- we must normalize our data as it is always required in neural network models\n",
        "- we can achieve this by dividing the RGB codes to 255 (which is the maximum RGB code minus the minimum RGB code)\n",
        "- normalize X_train and X_test\n",
        "- make sure that the values are float so that we can get decimal points after division"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PEFYNHRp5sYJ",
        "colab": {}
      },
      "source": [
        "x_train_normalized =  x_train_gret5.astype(\"float32\") / 255\n",
        "x_test_normalized = x_test_gret5.astype(\"float32\") / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vht1qNv7m-nB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_gret_normalized =  x_train_gret5.astype(\"float32\") / 255\n",
        "x_test_gret_normalized = x_test_gret5.astype(\"float32\") / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "173Sa0d0lbXb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a5f6cb6b-445c-4c18-b0dc-3e447f3441e9"
      },
      "source": [
        "x_train_gret_normalized[0]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.01176471],\n",
              "        [0.07058824],\n",
              "        [0.07058824],\n",
              "        [0.07058824],\n",
              "        [0.49411765],\n",
              "        [0.53333336],\n",
              "        [0.6862745 ],\n",
              "        [0.10196079],\n",
              "        [0.6509804 ],\n",
              "        [1.        ],\n",
              "        [0.96862745],\n",
              "        [0.49803922],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.11764706],\n",
              "        [0.14117648],\n",
              "        [0.36862746],\n",
              "        [0.6039216 ],\n",
              "        [0.6666667 ],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.88235295],\n",
              "        [0.6745098 ],\n",
              "        [0.99215686],\n",
              "        [0.9490196 ],\n",
              "        [0.7647059 ],\n",
              "        [0.2509804 ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.19215687],\n",
              "        [0.93333334],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.9843137 ],\n",
              "        [0.3647059 ],\n",
              "        [0.32156864],\n",
              "        [0.32156864],\n",
              "        [0.21960784],\n",
              "        [0.15294118],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.07058824],\n",
              "        [0.85882354],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.7764706 ],\n",
              "        [0.7137255 ],\n",
              "        [0.96862745],\n",
              "        [0.94509804],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.3137255 ],\n",
              "        [0.6117647 ],\n",
              "        [0.41960785],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.8039216 ],\n",
              "        [0.04313726],\n",
              "        [0.        ],\n",
              "        [0.16862746],\n",
              "        [0.6039216 ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.05490196],\n",
              "        [0.00392157],\n",
              "        [0.6039216 ],\n",
              "        [0.99215686],\n",
              "        [0.3529412 ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.54509807],\n",
              "        [0.99215686],\n",
              "        [0.74509805],\n",
              "        [0.00784314],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.04313726],\n",
              "        [0.74509805],\n",
              "        [0.99215686],\n",
              "        [0.27450982],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.13725491],\n",
              "        [0.94509804],\n",
              "        [0.88235295],\n",
              "        [0.627451  ],\n",
              "        [0.42352942],\n",
              "        [0.00392157],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.31764707],\n",
              "        [0.9411765 ],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.46666667],\n",
              "        [0.09803922],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.1764706 ],\n",
              "        [0.7294118 ],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.5882353 ],\n",
              "        [0.10588235],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.0627451 ],\n",
              "        [0.3647059 ],\n",
              "        [0.9882353 ],\n",
              "        [0.99215686],\n",
              "        [0.73333335],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.9764706 ],\n",
              "        [0.99215686],\n",
              "        [0.9764706 ],\n",
              "        [0.2509804 ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.18039216],\n",
              "        [0.50980395],\n",
              "        [0.7176471 ],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.8117647 ],\n",
              "        [0.00784314],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.15294118],\n",
              "        [0.5803922 ],\n",
              "        [0.8980392 ],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.98039216],\n",
              "        [0.7137255 ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.09411765],\n",
              "        [0.44705883],\n",
              "        [0.8666667 ],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.7882353 ],\n",
              "        [0.30588236],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.09019608],\n",
              "        [0.25882354],\n",
              "        [0.8352941 ],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.7764706 ],\n",
              "        [0.31764707],\n",
              "        [0.00784314],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.07058824],\n",
              "        [0.67058825],\n",
              "        [0.85882354],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.7647059 ],\n",
              "        [0.3137255 ],\n",
              "        [0.03529412],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.21568628],\n",
              "        [0.6745098 ],\n",
              "        [0.8862745 ],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.95686275],\n",
              "        [0.52156866],\n",
              "        [0.04313726],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.53333336],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.99215686],\n",
              "        [0.83137256],\n",
              "        [0.5294118 ],\n",
              "        [0.5176471 ],\n",
              "        [0.0627451 ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0OfdlF655sYM"
      },
      "source": [
        "### Print shape of data and number of images\n",
        "- print shape of X_train\n",
        "- print number of images in X_train\n",
        "- print number of images in X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bZEkCQ-P5sYO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61dcfb43-fd68-47bb-a568-8c74feb4d7eb"
      },
      "source": [
        "print(x_train_gret_normalized.shape)\n",
        "print(x_test_gret_normalized.shape)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(29404, 28, 28, 1)\n",
            "(4861, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c_3-0Qwo5sYQ"
      },
      "source": [
        "### One-hot encode the class vector\n",
        "- convert class vectors (integers) to binary class matrix\n",
        "- convert y_train and y_test\n",
        "- number of classes: 5\n",
        "- we are doing this to use categorical_crossentropy as loss\n",
        "\n",
        "Hint: you can use keras.utils.to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Zg36CjnlIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cbd1697-dd4c-4a1b-8067-e4b06ecc74fc"
      },
      "source": [
        "y_train_gret5"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 4, 0, ..., 0, 1, 3], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k46Me5Re5sYR",
        "colab": {}
      },
      "source": [
        "y_train2 = tf.keras.utils.to_categorical(y_train_gret5, num_classes=5)\n",
        "y_test2 = tf.keras.utils.to_categorical(y_test_gret5, num_classes=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzubfFnPnf6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e9db9aba-2f5b-44e5-a72d-06143a6dccaa"
      },
      "source": [
        "y_train2"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D9xEoW515sYS"
      },
      "source": [
        "### Fit the model\n",
        "- give train data - features and labels\n",
        "- batch size: 128\n",
        "- epochs: 10\n",
        "- give validation data - features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B6f-XAc-5sYT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "9a1b3ba7-30a3-40cc-b6a5-d2259b9d816c"
      },
      "source": [
        "#Training on the dataset\n",
        "\n",
        "hist = model.fit(x_train_gret_normalized, y_train2,\n",
        "          batch_size=32,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test_gret_normalized, y_test2))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 29404 samples, validate on 4861 samples\n",
            "Epoch 1/20\n",
            "  768/29404 [..............................] - ETA: 6s - loss: 1.6215 - acc: 0.4792"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "29404/29404 [==============================] - 4s 149us/step - loss: 0.3876 - acc: 0.8721 - val_loss: 0.1157 - val_acc: 0.9617\n",
            "Epoch 2/20\n",
            "29404/29404 [==============================] - 4s 138us/step - loss: 0.1670 - acc: 0.9486 - val_loss: 0.0748 - val_acc: 0.9774\n",
            "Epoch 3/20\n",
            "29404/29404 [==============================] - 4s 140us/step - loss: 0.1270 - acc: 0.9604 - val_loss: 0.0585 - val_acc: 0.9819\n",
            "Epoch 4/20\n",
            "29404/29404 [==============================] - 4s 140us/step - loss: 0.1065 - acc: 0.9677 - val_loss: 0.0523 - val_acc: 0.9833\n",
            "Epoch 5/20\n",
            "29404/29404 [==============================] - 4s 143us/step - loss: 0.0955 - acc: 0.9693 - val_loss: 0.0484 - val_acc: 0.9842\n",
            "Epoch 6/20\n",
            "29404/29404 [==============================] - 4s 143us/step - loss: 0.0844 - acc: 0.9729 - val_loss: 0.0469 - val_acc: 0.9848\n",
            "Epoch 7/20\n",
            "29404/29404 [==============================] - 4s 148us/step - loss: 0.0799 - acc: 0.9746 - val_loss: 0.0393 - val_acc: 0.9864\n",
            "Epoch 8/20\n",
            "29404/29404 [==============================] - 4s 140us/step - loss: 0.0730 - acc: 0.9762 - val_loss: 0.0379 - val_acc: 0.9850\n",
            "Epoch 9/20\n",
            "29404/29404 [==============================] - 4s 141us/step - loss: 0.0697 - acc: 0.9783 - val_loss: 0.0382 - val_acc: 0.9858\n",
            "Epoch 10/20\n",
            "29404/29404 [==============================] - 4s 140us/step - loss: 0.0627 - acc: 0.9806 - val_loss: 0.0323 - val_acc: 0.9883\n",
            "Epoch 11/20\n",
            "29404/29404 [==============================] - 4s 143us/step - loss: 0.0600 - acc: 0.9811 - val_loss: 0.0298 - val_acc: 0.9891\n",
            "Epoch 12/20\n",
            "29404/29404 [==============================] - 4s 149us/step - loss: 0.0561 - acc: 0.9820 - val_loss: 0.0298 - val_acc: 0.9901\n",
            "Epoch 13/20\n",
            "29404/29404 [==============================] - 4s 147us/step - loss: 0.0533 - acc: 0.9829 - val_loss: 0.0280 - val_acc: 0.9889\n",
            "Epoch 14/20\n",
            "29404/29404 [==============================] - 4s 141us/step - loss: 0.0531 - acc: 0.9828 - val_loss: 0.0304 - val_acc: 0.9889\n",
            "Epoch 15/20\n",
            "29404/29404 [==============================] - 4s 142us/step - loss: 0.0509 - acc: 0.9838 - val_loss: 0.0291 - val_acc: 0.9887\n",
            "Epoch 16/20\n",
            "29404/29404 [==============================] - 4s 142us/step - loss: 0.0488 - acc: 0.9845 - val_loss: 0.0273 - val_acc: 0.9905\n",
            "Epoch 17/20\n",
            "29404/29404 [==============================] - 4s 140us/step - loss: 0.0442 - acc: 0.9857 - val_loss: 0.0247 - val_acc: 0.9914\n",
            "Epoch 18/20\n",
            "29404/29404 [==============================] - 4s 140us/step - loss: 0.0463 - acc: 0.9853 - val_loss: 0.0264 - val_acc: 0.9909\n",
            "Epoch 19/20\n",
            "29404/29404 [==============================] - 4s 141us/step - loss: 0.0424 - acc: 0.9859 - val_loss: 0.0254 - val_acc: 0.9916\n",
            "Epoch 20/20\n",
            "29404/29404 [==============================] - 4s 143us/step - loss: 0.0441 - acc: 0.9853 - val_loss: 0.0236 - val_acc: 0.9920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "85ginrII5sYV"
      },
      "source": [
        "### Evaluate model\n",
        "- evaluate your model and get accuracy\n",
        "- use test features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k11-vrsm5sYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3aae6947-0a4c-4a8e-c4c4-ce0188425cd2"
      },
      "source": [
        "score = model.evaluate(x_test_gret_normalized, y_test2)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4861/4861 [==============================] - 0s 57us/step\n",
            "Test loss: 0.023593939738316513\n",
            "Test accuracy: 0.9919769594733594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dTNhSDqn5sYY"
      },
      "source": [
        "-----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FU-HwvIdH0M-"
      },
      "source": [
        "# Sentiment analysis \n",
        "\n",
        "The objective of the second problem is to perform Sentiment analysis from the tweets collected from the users targeted at various mobile devices.\n",
        "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aIWWfNks5sYa"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAQDiZHRH0M_"
      },
      "source": [
        "### Read the data\n",
        "- read tweets.csv\n",
        "- use latin encoding if it gives encoding error while loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3eXGIe-SH0NA",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUrRWFlbqtcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = pd.read_csv('tweets.csv',encoding='ISO-8859-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLDpDkXQq0VT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4164a543-ed3d-47d0-9abc-33fddbaa25fe"
      },
      "source": [
        "ds.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...                                   Negative emotion\n",
              "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...                                   Positive emotion\n",
              "2  @swonderlin Can not wait for #iPad 2 also. The...  ...                                   Positive emotion\n",
              "3  @sxsw I hope this year's festival isn't as cra...  ...                                   Negative emotion\n",
              "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...                                   Positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "39pqw0aE5sYe"
      },
      "source": [
        "### Drop null values\n",
        "- drop all the rows with null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BF_69oyI5sYf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab49427c-a066-4cc7-af6a-a24da1c72212"
      },
      "source": [
        "ds.shape"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9093, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrObNW1Krp_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "058f989a-ba04-4f4e-a2cc-a127a7400d4e"
      },
      "source": [
        "ds.isna().sum()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_text                                               1\n",
              "emotion_in_tweet_is_directed_at                       5802\n",
              "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5at3xu0vr0fi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0bm4bDiy5sYg"
      },
      "source": [
        "### Print the dataframe\n",
        "- print initial 5 rows of the data\n",
        "- use df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ceSlvAVa5sYh",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41d5458c-3112-4573-b4ed-ff0b36173979"
      },
      "source": [
        "ds.shape"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3291, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jcWfPVqG5sYi"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JBbAeip_5sYj"
      },
      "source": [
        "### Preprocess data\n",
        "- convert all text to lowercase - use .lower()\n",
        "- select only numbers, alphabets, and #+_ from text - use re.sub()\n",
        "- strip all the text - use .strip()\n",
        "    - this is for removing extra spaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PE4Bn_YT5sYj",
        "colab": {}
      },
      "source": [
        "ds['tweet_text'] = ds['tweet_text'].str.lower() #converting in lower case"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRdG7xKMvDbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "ds = ds.applymap(lambda x: re.sub(r\"[^0-9A-Za-z#+_ ]+\",\"\",str(x))) #r - brings the raw format of the data\n",
        "# import re\n",
        "# string = \"at what time?\"\n",
        "# match = re.sub(\"\\s\",\"!!!\",string)\n",
        "# print (match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF6ZZ_5w0U4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "#dg = ds.applymap(lambda x: re.sub(\"[^0-9a-z#+_ ]\",\" \",x)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtIZS8kh0cFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dg = ds.applymap(lambda x: x.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLxPXh_2w0wn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "73d5f7d5-ec71-4099-b080-58577abca313"
      },
      "source": [
        "df =  ds.re.sub(r\"[^0-9A-Za-z#+_ ]+\",\"\",ds)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-767d52d61f2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"[^0-9A-Za-z#+_ ]+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 're'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QlMvbtrK5sYl"
      },
      "source": [
        "print dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "afocjaUn5sYm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9b61c686-f76d-4fc7-f67d-fa9b5e328a8b"
      },
      "source": [
        "ds.head()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wesley83 i have a 3g iphone after 3 hrs tweeti...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jessedee know about fludapp  awesome ipadiphon...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>swonderlin can not wait for #ipad 2 also they ...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sxsw i hope this years festival isnt as crashy...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sxtxstate great stuff on fri #sxsw marissa may...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  wesley83 i have a 3g iphone after 3 hrs tweeti...  ...                                   Negative emotion\n",
              "1  jessedee know about fludapp  awesome ipadiphon...  ...                                   Positive emotion\n",
              "2  swonderlin can not wait for #ipad 2 also they ...  ...                                   Positive emotion\n",
              "3  sxsw i hope this years festival isnt as crashy...  ...                                   Negative emotion\n",
              "4  sxtxstate great stuff on fri #sxsw marissa may...  ...                                   Positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bcTUnvtg5sYn"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4gnaeSXZ5sYo"
      },
      "source": [
        "### Preprocess data\n",
        "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
        "    - select only those rows where value equal to \"positive emotion\" or \"negative emotion\"\n",
        "- find the value counts of \"positive emotion\" and \"negative emotion\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nLewJh_35sYp",
        "colab": {}
      },
      "source": [
        "df1 = ds.is_there_an_emotion_directed_at_a_brand_or_product"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le2wyZyz1itm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3558b19-9f7b-4b22-e549-e65962730122"
      },
      "source": [
        "ds.shape"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3291, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiBnA2cczuKh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "19496368-3ff6-44a6-e301-9c2358631000"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Negative emotion\n",
              "1    Positive emotion\n",
              "2    Positive emotion\n",
              "3    Negative emotion\n",
              "4    Positive emotion\n",
              "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3VFYB4eh5sYr",
        "colab": {}
      },
      "source": [
        "neg = (ds[ds[\"is_there_an_emotion_directed_at_a_brand_or_product\"] == \"Negative emotion\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2yRw_rGzgYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "940d06f8-f5fe-45e1-9ac3-6d9ab91b2740"
      },
      "source": [
        "neg.head()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wesley83 i have a 3g iphone after 3 hrs tweeti...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sxsw i hope this years festival isnt as crashy...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>i just noticed dst is coming this weekend how ...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>mention   false alarm google circles not comin...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>attending mention ipad design headaches #sxsw ...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0   wesley83 i have a 3g iphone after 3 hrs tweeti...  ...                                   Negative emotion\n",
              "3   sxsw i hope this years festival isnt as crashy...  ...                                   Negative emotion\n",
              "17  i just noticed dst is coming this weekend how ...  ...                                   Negative emotion\n",
              "38  mention   false alarm google circles not comin...  ...                                   Negative emotion\n",
              "67  attending mention ipad design headaches #sxsw ...  ...                                   Negative emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZAGZPMDzZUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos = (ds[ds[\"is_there_an_emotion_directed_at_a_brand_or_product\"] == \"Positive emotion\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvJuKTrazmGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "034dd5cd-9c47-49e9-cd10-310c25c6b05e"
      },
      "source": [
        "pos.head()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jessedee know about fludapp  awesome ipadiphon...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>swonderlin can not wait for #ipad 2 also they ...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sxtxstate great stuff on fri #sxsw marissa may...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>#sxsw is just starting #ctia is around the cor...</td>\n",
              "      <td>Android</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>beautifully smart and simple idea rt madebyman...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "1  jessedee know about fludapp  awesome ipadiphon...  ...                                   Positive emotion\n",
              "2  swonderlin can not wait for #ipad 2 also they ...  ...                                   Positive emotion\n",
              "4  sxtxstate great stuff on fri #sxsw marissa may...  ...                                   Positive emotion\n",
              "7  #sxsw is just starting #ctia is around the cor...  ...                                   Positive emotion\n",
              "8  beautifully smart and simple idea rt madebyman...  ...                                   Positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SILa_umvzZwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = ds[(ds[\"is_there_an_emotion_directed_at_a_brand_or_product\"] == \"Negative emotion\") | (ds[\"is_there_an_emotion_directed_at_a_brand_or_product\"] == \"Positive emotion\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GESN8QiyzZP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "5164c5a5-ba9c-48e2-cfce-ec95fe6c896e"
      },
      "source": [
        "df2"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wesley83 i have a 3g iphone after 3 hrs tweeti...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jessedee know about fludapp  awesome ipadiphon...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>swonderlin can not wait for #ipad 2 also they ...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sxsw i hope this years festival isnt as crashy...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sxtxstate great stuff on fri #sxsw marissa may...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9077</th>\n",
              "      <td>mention your pr guy just convinced me to switc...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9079</th>\n",
              "      <td>quotpapyrussort of like the ipadquot  nice lol...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9080</th>\n",
              "      <td>diller says google tv quotmight be run over by...</td>\n",
              "      <td>Other Google product or service</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9085</th>\n",
              "      <td>ive always used camera+ for my iphone bc it ha...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9088</th>\n",
              "      <td>ipad everywhere #sxsw link</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3191 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0     wesley83 i have a 3g iphone after 3 hrs tweeti...  ...                                   Negative emotion\n",
              "1     jessedee know about fludapp  awesome ipadiphon...  ...                                   Positive emotion\n",
              "2     swonderlin can not wait for #ipad 2 also they ...  ...                                   Positive emotion\n",
              "3     sxsw i hope this years festival isnt as crashy...  ...                                   Negative emotion\n",
              "4     sxtxstate great stuff on fri #sxsw marissa may...  ...                                   Positive emotion\n",
              "...                                                 ...  ...                                                ...\n",
              "9077  mention your pr guy just convinced me to switc...  ...                                   Positive emotion\n",
              "9079  quotpapyrussort of like the ipadquot  nice lol...  ...                                   Positive emotion\n",
              "9080  diller says google tv quotmight be run over by...  ...                                   Negative emotion\n",
              "9085  ive always used camera+ for my iphone bc it ha...  ...                                   Positive emotion\n",
              "9088                         ipad everywhere #sxsw link  ...                                   Positive emotion\n",
              "\n",
              "[3191 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKXHSw181oTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfa8b7dd-bd31-4562-a6a0-b2dd8b1049a4"
      },
      "source": [
        "df2.shape"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3191, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6icGcVTE5sYz"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rg0rSepj5sYz"
      },
      "source": [
        "### Encode labels\n",
        "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
        "    - change \"positive emotion\" to 1\n",
        "    - change \"negative emotion\" to 0\n",
        "- use map function to replace values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YftKwFv7H0N9",
        "colab": {}
      },
      "source": [
        "dict = {'Positive emotion' : 1, 'Negative emotion' : 0}\n",
        "df2['Review']=df2['is_there_an_emotion_directed_at_a_brand_or_product'].map(dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kJ-K7TO16m2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "05c32be7-7010-4d52-ceb5-32bdac56a147"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wesley83 i have a 3g iphone after 3 hrs tweeti...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jessedee know about fludapp  awesome ipadiphon...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>swonderlin can not wait for #ipad 2 also they ...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sxsw i hope this years festival isnt as crashy...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sxtxstate great stuff on fri #sxsw marissa may...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... Review\n",
              "0  wesley83 i have a 3g iphone after 3 hrs tweeti...  ...      0\n",
              "1  jessedee know about fludapp  awesome ipadiphon...  ...      1\n",
              "2  swonderlin can not wait for #ipad 2 also they ...  ...      1\n",
              "3  sxsw i hope this years festival isnt as crashy...  ...      0\n",
              "4  sxtxstate great stuff on fri #sxsw marissa may...  ...      1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isrOcJfk2yPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c8c6509d-0d1b-4db9-952b-623c9633f5eb"
      },
      "source": [
        "df2.Review.value_counts()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2672\n",
              "0     519\n",
              "Name: Review, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sC1qSe3h5sY2"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aWlAN_Ts5sY2"
      },
      "source": [
        "### Get feature and label\n",
        "- get column \"tweet_text\" as feature\n",
        "- get column \"is_there_an_emotion_directed_at_a_brand_or_product\" as label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9A3sOZzR5sY4",
        "colab": {}
      },
      "source": [
        "X = df2['tweet_text']\n",
        "Y = df2['Review']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YErwYLCH0N_"
      },
      "source": [
        "### Create train and test data\n",
        "- use train_test_split to get train and test set\n",
        "- set a random_state\n",
        "- test_size: 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lNkwrGgEH0OA",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VOtnwqY3LwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "360c827c-2222-4ef8-a20a-fabf811e4e5b"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2393,)\n",
            "(798,)\n",
            "(2393,)\n",
            "(798,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gMok2IX35sY8"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dSqYjPuT5sY8"
      },
      "source": [
        "### Vectorize data\n",
        "- create document-term matrix\n",
        "- use CountVectorizer()\n",
        "    - ngram_range: (1, 2)\n",
        "    - stop_words: 'english'\n",
        "    - min_df: 2   \n",
        "- do fit_transform on X_train\n",
        "- do transform on X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bb9PnnqT5sY8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d365da4a-d4aa-40b2-a7ee-024a189eef5b"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "vect = CountVectorizer(ngram_range = (1, 2), stop_words = 'english', min_df = 2)\n",
        "\n",
        "# creating document-term matrices:\n",
        "X_train_dtm = vect.fit_transform(X_train)\n",
        "X_test_dtm = vect.transform(X_test)\n",
        "X_train_dtm.shape"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2393, 5434)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyeiYpBo478Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99a5c410-fd20-4f82-b0cf-0d686f6406d2"
      },
      "source": [
        "X_test_dtm.shape"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(798, 5434)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qanDXve15sY_"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uMaRNFkV5sY_"
      },
      "source": [
        "### Select classifier logistic regression\n",
        "- use logistic regression for predicting sentiment of the given tweet\n",
        "- initialize classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GT3dNgB55sZA",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# Fit the model on 30%\n",
        "model = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pqQ6_HX35sZD"
      },
      "source": [
        "### Fit the classifer\n",
        "- fit logistic regression classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EIzvnNkq5sZD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d44043ca-cd54-4643-d7bb-11dd90308311"
      },
      "source": [
        "model.fit(X_train_dtm, y_train)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SZpMsYQF5sZF"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KGnQnUww5sZF"
      },
      "source": [
        "### Select classifier naive bayes\n",
        "- use naive bayes for predicting sentiment of the given tweet\n",
        "- initialize classifier\n",
        "- use MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2AbVYssaH0OE",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb = MultinomialNB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QEaG942m5sZI"
      },
      "source": [
        "### Fit the classifer\n",
        "- fit naive bayes classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rLwRBj1R5sZI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "640a3084-e60b-4df8-897a-21812564cfb2"
      },
      "source": [
        "nb.fit(X_train_dtm, y_train)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A7mgwYDJ5sZM"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sZkA3tce5sZN"
      },
      "source": [
        "### Make predictions on logistic regression\n",
        "- use your trained logistic regression model to make predictions on X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l3f0M1ch5sZO",
        "colab": {}
      },
      "source": [
        "y_logistic_pred_class = model.predict(X_test_dtm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yxWVWg452h5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "b05f6ce1-df90-435a-9f53-4c2377ba88fa"
      },
      "source": [
        "y_logistic_pred_class"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lrIxjMUB5sZQ"
      },
      "source": [
        "### Make predictions on naive bayes\n",
        "- use your trained naive bayes model to make predictions on X_test\n",
        "- use a different variable name to store predictions so that they are kept separately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZSQnwyLU5sZQ",
        "colab": {}
      },
      "source": [
        "y_bayes_pred_class = nb.predict(X_test_dtm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb5aiAAc5-Ma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "51b77b6b-e5e0-4de7-fc3a-83070ea52b24"
      },
      "source": [
        "y_bayes_pred_class"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rwXQUE7b5sZS"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E6SITIE75sZT"
      },
      "source": [
        "### Calculate accuracy of logistic regression\n",
        "- check accuracy of logistic regression classifer\n",
        "- use sklearn.metrics.accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "clv2X0kKH0Ok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e1031b3-badb-40a3-e780-ef81a69d7658"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, y_logistic_pred_class))\n"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8659147869674185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Fd_Gnd05sZV"
      },
      "source": [
        "### Calculate accuracy of naive bayes\n",
        "- check accuracy of naive bayes classifer\n",
        "- use sklearn.metrics.accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d32uBpHi5sZW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "175b6e2e-4755-4d6d-f881-229963571b8d"
      },
      "source": [
        "print ('Accuracy: ', accuracy_score(y_test, y_bayes_pred_class))"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8571428571428571\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}